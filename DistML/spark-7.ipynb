{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "spark_path = os.environ['SPARK_HOME']\n",
    "sys.path.append(spark_path + \"/bin\")\n",
    "sys.path.append(spark_path + \"/python\")\n",
    "sys.path.append(spark_path + \"/python/pyspark/\")\n",
    "sys.path.append(spark_path + \"/python/lib\")\n",
    "sys.path.append(spark_path + \"/python/lib/pyspark.zip\")\n",
    "sys.path.append(spark_path + \"/python/lib/py4j-0.10.9-src.zip\")\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_cores = 8\n",
    "memory_gb = 16\n",
    "conf = (pyspark.SparkConf().setMaster('local[{}]'.format(number_cores)).set('spark.driver.memory', '{}g'.format(memory_gb)))\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir: cannot access '.data': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!dir .\\data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- deposit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('./data/bank.csv', header = True, inferSchema = True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import SVMWithSGD\n",
    "\n",
    "data = [\n",
    "    LabeledPoint(0.0, [0.0]),\n",
    "    LabeledPoint(1.0, [1.0]),\n",
    "    LabeledPoint(1.0, [2.0]),\n",
    "    LabeledPoint(1.0, [3.0])\n",
    "]\n",
    "svm = SVMWithSGD.train(sc.parallelize(data), iterations=10)\n",
    "svm.predict([1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict(sc.parallelize([[1.0]])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4407421280634385"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy \n",
    "\n",
    "svm.clearThreshold()\n",
    "svm.predict(numpy.array([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Matrix, Matrices, Vectors, DenseMatrix, SparseVector\n",
    "\n",
    "sparse_data = [\n",
    "    LabeledPoint(0.0, SparseVector(2, {0: -1.0})),\n",
    "    LabeledPoint(1.0, SparseVector(2, {1: 1.0})),\n",
    "    LabeledPoint(0.0, SparseVector(2, {0: 0.0})),\n",
    "    LabeledPoint(1.0, SparseVector(2, {1: 2.0}))\n",
    "]\n",
    "svm = SVMWithSGD.train(sc.parallelize(sparse_data), iterations=10)\n",
    "svm.predict(SparseVector(2, {1: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from pyspark.mllib.classification import SVMModel\n",
    "#import os, tempfile\n",
    "#path = tempfile.mkdtemp()\n",
    "#svm.save(sc, path)\n",
    "#sameModel = SVMModel.load(sc, path)\n",
    "svm.predict(SparseVector(2, {1: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict(SparseVector(2, {0: -1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- deposit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Can you predict whether a client will subscribe to a term deposit (feature deposit)?\n",
    "\n",
    "### Problems:\n",
    "- What data should the bank data be converted to?\n",
    "- How to handle categorical data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dense or sparse? Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data organization\n",
    "\n",
    "LabeledPoint(deposit, [age, job, marital, education, ....])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=59, job='admin.', marital='married', education='secondary', default='no', balance=2343, housing='yes', loan='no', contact='unknown', day=5, month='may', duration=1042, campaign=1, pdays=-1, previous=0, poutcome='unknown', deposit='yes'),\n",
       " Row(age=56, job='admin.', marital='married', education='secondary', default='no', balance=45, housing='no', loan='no', contact='unknown', day=5, month='may', duration=1467, campaign=1, pdays=-1, previous=0, poutcome='unknown', deposit='yes'),\n",
       " Row(age=41, job='technician', marital='married', education='secondary', default='no', balance=1270, housing='yes', loan='no', contact='unknown', day=5, month='may', duration=1389, campaign=1, pdays=-1, previous=0, poutcome='unknown', deposit='yes'),\n",
       " Row(age=55, job='services', marital='married', education='secondary', default='no', balance=2476, housing='yes', loan='no', contact='unknown', day=5, month='may', duration=579, campaign=1, pdays=-1, previous=0, poutcome='unknown', deposit='yes'),\n",
       " Row(age=54, job='admin.', marital='married', education='tertiary', default='no', balance=184, housing='no', loan='no', contact='unknown', day=5, month='may', duration=673, campaign=2, pdays=-1, previous=0, poutcome='unknown', deposit='yes')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(deposit='no'), Row(deposit='yes')]\n"
     ]
    }
   ],
   "source": [
    "unique_deposit = df.select('deposit').distinct().collect()\n",
    "print(unique_deposit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'deposit']\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'deposit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dictionary = {}\n",
    "\n",
    "for c in cat_columns:\n",
    "    unique_c = df.select(c).distinct().collect()\n",
    "    #print(c + \": \" + str(len(unique_c)))\n",
    "    cat_dictionary[c] = {}\n",
    "    i = 0\n",
    "    for v in unique_c:\n",
    "        cat_dictionary[c][v[c]] = i\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job': {'management': 0, 'retired': 1, 'unknown': 2, 'self-employed': 3, 'student': 4, 'blue-collar': 5, 'entrepreneur': 6, 'admin.': 7, 'technician': 8, 'services': 9, 'housemaid': 10, 'unemployed': 11}, 'marital': {'divorced': 0, 'married': 1, 'single': 2}, 'education': {'unknown': 0, 'tertiary': 1, 'secondary': 2, 'primary': 3}, 'default': {'no': 0, 'yes': 1}, 'housing': {'no': 0, 'yes': 1}, 'loan': {'no': 0, 'yes': 1}, 'contact': {'unknown': 0, 'cellular': 1, 'telephone': 2}, 'month': {'jun': 0, 'aug': 1, 'may': 2, 'feb': 3, 'sep': 4, 'mar': 5, 'oct': 6, 'jul': 7, 'nov': 8, 'apr': 9, 'dec': 10, 'jan': 11}, 'poutcome': {'success': 0, 'unknown': 1, 'other': 2, 'failure': 3}, 'deposit': {'no': 0, 'yes': 1}}\n"
     ]
    }
   ],
   "source": [
    "# feature vector that we will multiply the weights to\n",
    "print(cat_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPrep(r):\n",
    "    key = 0\n",
    "    value = []\n",
    "    for c in columns:\n",
    "        if c == 'deposit':\n",
    "            key = cat_dictionary[c][r[columns.index(c)]]\n",
    "        else:\n",
    "            if c in cat_columns:\n",
    "                value.append(cat_dictionary[c][r[columns.index(c)]])\n",
    "            else:\n",
    "                value.append(r[columns.index(c)])\n",
    "    return LabeledPoint(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dictionary['deposit']['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [59.0,7.0,1.0,2.0,0.0,2343.0,1.0,0.0,0.0,5.0,2.0,1042.0,1.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [56.0,7.0,1.0,2.0,0.0,45.0,0.0,0.0,0.0,5.0,2.0,1467.0,1.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [41.0,8.0,1.0,2.0,0.0,1270.0,1.0,0.0,0.0,5.0,2.0,1389.0,1.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [55.0,9.0,1.0,2.0,0.0,2476.0,1.0,0.0,0.0,5.0,2.0,579.0,1.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [54.0,7.0,1.0,1.0,0.0,184.0,0.0,0.0,0.0,5.0,2.0,673.0,2.0,-1.0,0.0,1.0])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# values of each feature for each row\n",
    "df_clean = df.rdd.map(dataPrep)\n",
    "df_clean.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns.index(\"deposit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training set and testing set (in reality you want 3, training, testing, and validating)\n",
    "df_svm = df_clean.randomSplit([0.8, 0.2], 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11162\n",
      "8925\n",
      "2237\n"
     ]
    }
   ],
   "source": [
    "print(df_clean.count())\n",
    "print(df_svm[0].count())\n",
    "print(df_svm[1].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_bank = SVMWithSGD.train(df_svm[0], iterations=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_bank.predict([41.0,8.0,1.0,2.0,0.0,1270.0,1.0,0.0,0.0,5.0,2.0,1389.0,1.0,-1.0,0.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testPrediction(p):\n",
    "    prediction = svm_bank.predict(p.features)\n",
    "    if prediction == p.label:\n",
    "        return (\"correct\", 1)\n",
    "    else:\n",
    "        return (\"incorrect\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('correct', 1272), ('incorrect', 965)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = df_svm[1].map(testPrediction).reduceByKey(lambda x, y: x + y)\n",
    "df_results.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5686186857398301"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1272 / 2237.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [41.0,5.0,1.0,2.0,0.0,1384.0,1.0,0.0,0.0,15.0,2.0,1162.0,4.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [45.0,5.0,0.0,3.0,0.0,594.0,1.0,0.0,0.0,29.0,2.0,833.0,2.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [28.0,3.0,1.0,2.0,0.0,123.0,0.0,1.0,2.0,22.0,6.0,313.0,1.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [37.0,9.0,1.0,2.0,0.0,1970.0,1.0,0.0,2.0,5.0,8.0,253.0,1.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [59.0,1.0,0.0,2.0,0.0,514.0,0.0,0.0,1.0,4.0,2.0,673.0,6.0,90.0,1.0,0.0]),\n",
       " LabeledPoint(1.0, [36.0,0.0,1.0,1.0,0.0,0.0,1.0,0.0,1.0,8.0,2.0,308.0,3.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [54.0,11.0,1.0,2.0,0.0,582.0,1.0,0.0,1.0,15.0,2.0,693.0,5.0,372.0,2.0,3.0]),\n",
       " LabeledPoint(1.0, [26.0,0.0,2.0,1.0,0.0,1623.0,0.0,0.0,1.0,2.0,0.0,479.0,1.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [72.0,1.0,1.0,0.0,0.0,1940.0,0.0,0.0,2.0,4.0,10.0,705.0,2.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [29.0,11.0,2.0,0.0,0.0,1584.0,0.0,0.0,1.0,6.0,4.0,245.0,1.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [38.0,6.0,2.0,2.0,0.0,2543.0,0.0,0.0,1.0,11.0,8.0,357.0,3.0,93.0,5.0,0.0]),\n",
       " LabeledPoint(1.0, [31.0,8.0,2.0,1.0,0.0,985.0,1.0,0.0,1.0,17.0,9.0,997.0,1.0,57.0,2.0,3.0]),\n",
       " LabeledPoint(0.0, [38.0,3.0,1.0,2.0,0.0,30.0,0.0,0.0,0.0,16.0,0.0,91.0,1.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(0.0, [29.0,7.0,1.0,2.0,0.0,6429.0,1.0,1.0,1.0,14.0,2.0,535.0,1.0,352.0,2.0,3.0]),\n",
       " LabeledPoint(0.0, [33.0,8.0,0.0,2.0,0.0,522.0,0.0,1.0,1.0,7.0,7.0,559.0,4.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(0.0, [39.0,9.0,1.0,3.0,0.0,1951.0,1.0,0.0,0.0,23.0,2.0,208.0,2.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(0.0, [55.0,8.0,2.0,2.0,0.0,1199.0,0.0,1.0,2.0,4.0,2.0,159.0,10.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(0.0, [78.0,1.0,1.0,0.0,0.0,38.0,0.0,0.0,2.0,4.0,1.0,156.0,1.0,1.0,3.0,2.0]),\n",
       " LabeledPoint(0.0, [39.0,11.0,2.0,2.0,0.0,2645.0,1.0,0.0,0.0,21.0,2.0,339.0,3.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(0.0, [53.0,0.0,1.0,1.0,0.0,232.0,1.0,0.0,2.0,29.0,11.0,32.0,1.0,-1.0,0.0,1.0]),\n",
       " LabeledPoint(0.0, [34.0,8.0,2.0,2.0,0.0,664.0,1.0,1.0,1.0,11.0,2.0,88.0,2.0,343.0,2.0,2.0]),\n",
       " LabeledPoint(0.0, [49.0,3.0,1.0,2.0,0.0,2061.0,1.0,1.0,0.0,30.0,2.0,137.0,3.0,-1.0,0.0,1.0])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_svm[1].sample(False, 0.01).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = LabeledPoint(1.0, [34.0,9.0,1.0,2.0,0.0,-538.0,1.0,0.0,0.0,26.0,2.0,682.0,1.0,-1.0,0.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledPoint(1.0, [34.0,9.0,1.0,2.0,0.0,-538.0,1.0,0.0,0.0,26.0,2.0,682.0,1.0,-1.0,0.0,1.0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_bank.predict([34.0,9.0,1.0,2.0,0.0,-538.0,1.0,0.0,0.0,26.0,2.0,682.0,1.0,-1.0,0.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
